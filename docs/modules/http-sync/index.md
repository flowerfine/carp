# Http-Sync

核心概念

* 进度管理。当前同步位置，进度延迟
* 子任务拆分。拆分数量，拆分步长。
* 任务执行器。map-reduce 实现
* 请求接口。返回结果
* 数据落库
* 异常事件



随着企业的发展，对信息系统的需求也在不断提高，无论是种类还是数据量。如企业组织管理选择钉钉、企业微信、飞书，企业招聘采用Boss直聘，内部报销会采用钉钉、企业微信上的应用如易快报，OA管理使用北森，财务报表使用金蝶；若公司为电商公司则会考虑在快手、抖音、拼多多、淘宝等开店，还会开启直播。

现代企业无法完全脱离信息系统实现运转，企业在使用这些信息系统的时候也会被绑定，如从企业微信上查看员工信息、考勤、审批报销流程，企业获取数据也需要依赖这些系统，企业内部进行数据流转、绩效考核、管理报表编制的时候，需从系统中直接查看数据或者导出数据。

企业发展过程中，会不断地追求效率，增加自动化，像从企业微信、抖音、拼多多上导数据的行为由人工导（如某财务需在月初编制上月财务报表，需携带集团几十部手机在月初挨个登陆快手店铺导账单，稍后在邮箱接收快手店铺账单数据，整理后分发给其他财务人员）耗时耗力，易出错，需改为自动化流程：

* RPA 技术。自动登录系统操作数据导出
* 开放平台。对接开放平台，同步数据

此模块积累对接开放平台，快速、稳定、易运维实现**数据同步**的经验。开放平台提供各种各样的接口，如电商开放平台商品类接口：创建商品，更新商品图片，上下架商品，获取商品列表。此模块以**数据同步**为目的，因此只考虑通过 `获取商品列表` 获取商品数据，其他接口不在此模块功能范围内。

作者来自大数据团队，对接众多开放平台，同步企业自身数据供团队和公司数据分析使用，`http-sync` 项目即是通过 `HTTP` 对接开放平台实现数据同步的开源项目，同时易改造成支持 `dubbo`、`grpc` 等其他通信协议场景

## 对接过的开放平台

项目中并未添加所有的开放平台，只是添加了个最常见的场景

* 快手
  * [开放平台](https://open.kuaishou.com/platform/openApi?menu=5)
  * [电商开放平台](https://open.kwaixiaodian.com/docs/dev?pageSign=a068e6b0409a9ee55f5b6f5760ff9d391614263559910)
  * [本地生活开放平台](https://open.kwailocallife.com/)
  * [磁力引擎开放平台](https://developers.e.kuaishou.com/welcome)
* [淘宝](https://open.taobao.com/)
  * 聚石塔
  * 聚石塔自定义接口

* 聚水潭
  * [开放平台-旧](https://open.jushuitan.com/document.html)
  * [开放平台-新](https://openweb.jushuitan.com/index)
* [有赞](https://doc.youzanyun.com/home)
* [京东联盟](https://union.jd.com/openplatform)
* [企业微信](https://developer.work.weixin.qq.com/)。获取组织架构，企业员工
* [北森](https://open.italent.cn/#/open-document?menu=develop-guide)。组织架构，考勤信息
* [易快报](https://docs.ekuaibao.com/)
* 金蝶
  * [金蝶云星瀚](https://mcn818.kdcloud.com/)
  * [工单系统](https://ticket.kingdee.com)
  * [开发者社区](https://developer.kingdee.com)

* [天眼查](https://open.tianyancha.com/)
* [得物](https://open.dewu.com/)
* [七鱼](https://qiyukf.com/docs/)

### 接口总结

开放平台提供的接口各异，但是也大致相似，这里对开放平台提供的接口进行总结。

从接口返回的数量进行分类，可分为：

* 详情接口。一次只返回单个对象的数据，如订单详情、员工信息
* 列表接口。一次返回一批数据，如订单列表，员工列表
  * 翻页。按照数据量，平台在提供接口时会考虑是否支持翻页。如获取物流仓库列表，仓库数据量在 100 以内，又或者订单评论的子评论，平台会一次性返回，如商品列表，商品数量会有几百个，平台会提供翻页功能
  * 翻页参数。pageSize + pageNum，offset + limit，cursor（或 scrollId） + size，has_next + size
    * 在快手-电商开放平台实现中大量使用 cursor + size 方式。如订单场景中，参数如下：
      * queryType。1：按创建时间查找，2：按更新时间查找。默认创建时间，值为1时只允许获取创建时间90天内的订单数据，值为2时仅允许获取更新时间90天内且创建时间240天内的订单数据
      * beginTime
      * endTime
      * sort。1：时间降序，2：时间升序。默认降序
      * pageSize。每页请求数量。最多一页50条
      * cursor。游标内容 第一次传空串，之后传上一次的cursor返回值，若返回“nomore”则标识到底。实例数据：`157356441188_2021345676543`。
    * 为获取数据的实时变动，按照 **updateTime** 作为时间范围，采取**降序**排序平台。因为数据本身的 updateTime 随时可能会变，**同步数据场景**为保证不漏数据需采用降序，**从后往前翻页**。参考淘宝开放平台接口：[taobao.trades.sold.increment.get](https://open.taobao.com/api.htm?docId=128&docType=2&source=search)
    * 实现时首次查询使用 `where updateTime >= {startUpdateTime} and updateTime < {endUpdateTime} order by updateTime desc, id limit {size}`，同时返回最后一条数据的 id + updateTime 作为 cursor。下次查询时会从 cursor 中解析出 id 和 updateTime，查询使用 `where updateTime >= {startUpdateTime} and updateTime <= {cursorUpdateTime} and id > {id} order by updateTime desc, id limit {size}`

在接口有新增数据时，无法每次全量拉取，开放平台一般会提供按照时间进行滚动查询的接口，如订单接口：

* 创建时间、更新时间。
* 业务时间。订单支付时间、库存出库时间、账单结算时间。

开放平台的数据一定情况下会删除，比如用户主动删除商品，某个仓库商品库存变为 0，组织结构中组织变更、员工离职，都会导致数据删除。开放平台接口不会提供被删除的数据，因此同步数据时无法感知数据删除，会导致同步的数据慢慢多于开放平台的数据。比如随着商品的创建和删除，开放平台中商品数据只有 100，但是在 3 年时间内同步系统同步的商品数据有 3000，多出来的即是开放平台 3 年内出现过但被删除的数据。

删除数据需要及时标记被删除的数据，需进行全量同步，即每次同步需同步接口全部数据。处理方式有 2 种：

* 同步时间。开始全量同步时，设置本次全量同步时间。全量同步结束时，对未标记删除的数据中没有更新为最新的全量同步时间数据，标记为删除数据。
* 快照。存储数据时，每次都存储数据的完整快照。查询时需携带快照信息，可以查看对应快照的数据。
  * 为保证 mysql 等关系型存储的数据规模，快照数据也可由数仓团队存储，关系型存储中每次同步时都把表中数据清空，存储最新数据

回刷数据。开放平台接口无法保证数据不遗漏，或者开放平台接口会发生变更，需要通过回刷数据保证不遗漏或者同步最新数据。

限流。开放平台接口为保证自身平台稳定性会设置限流。限流分为 2 个层次：

* 开放平台层次。如订单详情接口，开放平台本身能力只支持每秒 600 次（QPS： 600）
* 用户层次。开放平台设置每个用户的初始限流为每秒 10 次（QPS：10），用户总数可能超过 3000，部分数据量比较大的用户限流可以通过申请提升至每秒 100 次（QPS：100）

同步应用需设置好重试策略以



## 同步要点

* 鉴权方式
* 同步方式
* 单线程、多线程
* 数据存储

## 同步任务

* 时间+分页。如果某个时间范围数据量过大，存在深翻页，开放平台会增加限制（开放平台开发人员线下通知调用方调整，开放平台本身增加限制，至多翻 100 页）。在确定时间范围时，可以通过请求接口，根据接口数据量确定时间范围是否合理。
* 反复同步
* 详情接口

核心即是 **map-reduce**。

### 数据关联场景

如先同步部门员工和员工考勤信息数据，在同步员工的组织数据。因为**数据权限**原因，无法直接同步所有员工和组织信息，只允许同步某个部门全部员工信息，在通过员工信息的组织信息字段（orgId）同步员工所在的组织信息。

这里有 2 个限制：

* 同步部门员工信息时，接口会返回一个 cursor，第一次请求时传空，后续每次请求将上次请求响应中的 cursor 带入。cursor 具有时效性，必须在一定时间内完成所有部门员工信息的同步。
* 同时开放平台有相应的限流，无法大规模地调用接口。

因为上述 2 个限制，难以粗暴地同步员工信息后，直接同步员工对应的部门信息：一个是需快速从开放平台拉取所有员工信息，另一个是部门接口限流低，处理员工信息时不好每个都调用一次。

因为一个部门下会有很多员工，部门数据量会比部门员工数据量少的多。因此在同步员工信息时，将员工的部门id（orgId）存储下来，同步结束后，在根据部门id 同步对应的部门信息。

### 详情接口场景

数据分批扫描：

* 按照时间范围分批次。每批次数据由开始时间和结束时间决定。每批次数据量由数据本身分布决定，可能出现某个批次数据量特别大，存在数据热点现象。优点是可以支持并发，即同时可以处理多个批次。
* 按照数据量分批次。每次处理固定数据量数据，如一次处理 1k 条。扫描数据的时候采用 `timestamp >= #{startTime} order by timestamp limit 1000`，下一次扫描的开始时间即为上一次扫描最后一条数据的时间。优点是不存在数据热点，每次处理数据量相同，缺点是不支持并发，一次只能处理一个批次。
  * 时间限制也可以增加结束时间，对数据扫描时间进行限制。`timestamp >= #{startTime} and timestamp < #{endTime} order by timestamp limit 1000`